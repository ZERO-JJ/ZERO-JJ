(1)DNN:
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import scale
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import StratifiedKFold
import utils
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import accuracy_score, precision_score, recall_score,  matthews_corrcoef, f1_score  
from sklearn.metrics import confusion_matrix 
    
def calculate_performance(y_true, y_pred):
    CC=confusion_matrix(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)  
    sensitivity=CC[0,0]/(CC[0,0]+CC[0,1])
    mcc = matthews_corrcoef(y_true, y_pred)
    Sp=CC[1,1]/(CC[1,0]+CC[1,1])
    return   acc,sensitivity,mcc,Sp

def categorical_probas_to_classes(p):
    return np.argmax(p, axis=1)

def to_categorical(y, num_classes=None, dtype='float32'):
  y = np.array(y, dtype='int')
  input_shape = y.shape
  if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:
    input_shape = tuple(input_shape[:-1])
  y = y.ravel()
  if not num_classes:
    num_classes = np.max(y) + 1
  n = y.shape[0]
  categorical = np.zeros((n, num_classes), dtype=dtype)
  categorical[np.arange(n), y] = 1
  output_shape = input_shape + (num_classes,)
  categorical = np.reshape(categorical, output_shape)
  return categorical

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Flatten
import numpy as np
from keras.layers import Conv1D, MaxPooling1D,Dropout
from keras.models import Model

model = Sequential()
model.add(Dense(32, activation = 'relu',name="Dense_32"))
model.add(Dropout(0.5))
model.add(Dense(16, activation = 'relu',name="Dense_16"))
model.add(Dropout(0.5))
model.add(Dense(8, activation = 'relu',name="Dense_8"))
model.add(Dropout(0.5))
model.add(Dense(2, activation = 'sigmoid',name="Dense_2"))
model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics =['accuracy'])#rmsprop

data_=pd.read_csv(r"C:\Users\86153\Desktop\S. cerevisiae(2).csv",header=None)
data=np.array(data_)
data=data[1:,1:]
[m1,n1]=np.shape(data)
label1=np.ones((100,1))#495个正样本
label2=np.zeros((100,1))#495个正样本负样本
label=np.append(label1,label2)
shu=scale(data)
X=shu
y=label
print(y.shape)
sepscores = []
ytest=np.ones((1,2))*0.5
yscore=np.ones((1,2))*0.5
skf= StratifiedKFold(n_splits=10)
for train, test in skf.split(X,y): 
    y_train=to_categorical(y[train])#generate the resonable results
    cv_clf = model
    hist=cv_clf.fit(X[train], 
                    y_train,
                    epochs=30)
    y_score=cv_clf.predict(X[test])#the output of  probability
    y_class= categorical_probas_to_classes(y_score)
    y_test=to_categorical(y[test])#generate the test 
    ytest=np.vstack((ytest,y_test))
    y_test_tmp=y[test]       
    yscore=np.vstack((yscore,y_score))
    acc,sensitivity,mcc,Sp=calculate_performance( y_class, y_test_tmp)
    fpr, tpr, _ = roc_curve(y_test[:,0], y_score[:,0])
    fpr2, tpr2, _ = roc_curve(y_test[:,0], y_score[:,0])
    roc_auc = auc(fpr2, tpr2)
    y_class= categorical_probas_to_classes(y_score)
    acc,sensitivity,mcc,Sp =calculate_performance( y_class, y_test_tmp)
    sepscores.append([acc, sensitivity, mcc,Sp,roc_auc])
    print('DNN:acc=%f,sensitivity=%f,mcc=%f,Sp=%f,roc_auc=%f'
          % (acc,sensitivity,mcc,Sp,roc_auc))  
scores=np.array(sepscores)
print("acc=%.2f%% (+/- %.2f%%)" % (np.mean(scores, axis=0)[0]*100,np.std(scores, axis=0)[0]*100))
print("sensitivity=%.2f%% (+/- %.2f%%)" % (np.mean(scores, axis=0)[1]*100,np.std(scores, axis=0)[1]*100))
print("mcc=%.2f%% (+/- %.2f%%)" % (np.mean(scores, axis=0)[2]*100,np.std(scores, axis=0)[2]*100))
print("Sp=%.2f%% (+/- %.2f%%)" % (np.mean(scores, axis=0)[3]*100,np.std(scores, axis=0)[3]*100))
print("roc_auc=%.2f%% (+/- %.2f%%)" % (np.mean(scores, axis=0)[4]*100,np.std(scores, axis=0)[4]*100))



(2)LSTM:
def model():
    model = Sequential()
    model.add(LSTM(32,return_sequences=True)) 
    model.add(Dropout(0.5))
    model.add(Flatten())
    model.add(Dense(8, activation = 'tanh',name="Dense_8"))
    model.add(Dense(4, activation = 'softmax',name="Dense_4"))
    model.add(Dense(2, activation = 'sigmoid',name="Dense_2"))
    model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics =['accuracy'])#rmsprop
    return model



(3)XGboost+RF+GBDT+SVM:
import pandas as pd
data=pd.read_csv(r"C:\Users\86153\Desktop\H(2).csv")
X=data.iloc[:,1:]
y=data.iloc[:,0]
from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier
dtree=DecisionTreeClassifier()
from sklearn.svm import SVC
from sklearn.svm import SVR

#RF
from sklearn.ensemble import RandomForestClassifier
RF=RandomForestClassifier(n_estimators=150)

#XGboost
from xgboost import XGBClassifier
xgb = XGBClassifier(learning_rate =0.1,n_estimators=150)

#GBDT
from sklearn.ensemble import GradientBoostingClassifier
GBDT = GradientBoostingClassifier()

#SVM
svm = SVC(kernel="poly", degree=2, random_state=123)

RF.fit(X,y)
xgb.fit(X,y)
GBDT.fit(X,y)
svm.fit(X,y)
from sklearn import  model_selection
from sklearn.metrics import confusion_matrix

pred1 = model_selection.cross_val_predict(RF, X, y, cv=10)
CC=confusion_matrix(y, pred2)
ACC=(CC[0,0]+CC[1,1])/(CC[0,0]+CC[0,1]+CC[1,0]+CC[1,1])
Sn=CC[0,0]/(CC[0,0]+CC[0,1])
Sp=CC[1,1]/(CC[1,0]+CC[1,1])
MCC=(CC[0,0]*CC[1,1]-CC[1,0]*CC[0,1])/((CC[0,0]+CC[1,0])*(CC[0,0]+CC[0,1])*(CC[1,0]+CC[1,1])*(CC[0,1]+CC[1,1]))**(1/2)
print('ACC:',ACC)
print('Sn:',Sn)
print('Sp:',Sp)
print('MCC:',MCC)


pred2 = model_selection.cross_val_predict(xgb, X, y, cv=10)
CC=confusion_matrix(y, pred3)
ACC=(CC[0,0]+CC[1,1])/(CC[0,0]+CC[0,1]+CC[1,0]+CC[1,1])
Sn=CC[0,0]/(CC[0,0]+CC[0,1])
Sp=CC[1,1]/(CC[1,0]+CC[1,1])
MCC=(CC[0,0]*CC[1,1]-CC[1,0]*CC[0,1])/((CC[0,0]+CC[1,0])*(CC[0,0]+CC[0,1])*(CC[1,0]+CC[1,1])*(CC[0,1]+CC[1,1]))**(1/2)
print('ACC:',ACC)
print('Sn:',Sn)
print('Sp:',Sp)
print('MCC:',MCC)


pred3 = model_selection.cross_val_predict(GBDT, X, y, cv=10)
CC=confusion_matrix(y, pred4)
ACC=(CC[0,0]+CC[1,1])/(CC[0,0]+CC[0,1]+CC[1,0]+CC[1,1])
Sn=CC[0,0]/(CC[0,0]+CC[0,1])
Sp=CC[1,1]/(CC[1,0]+CC[1,1])
MCC=(CC[0,0]*CC[1,1]-CC[1,0]*CC[0,1])/((CC[0,0]+CC[1,0])*(CC[0,0]+CC[0,1])*(CC[1,0]+CC[1,1])*(CC[0,1]+CC[1,1]))**(1/2)
print('ACC:',ACC)
print('Sn:',Sn)
print('Sp:',Sp)
print('MCC:',MCC)


pred4 = model_selection.cross_val_predict(svm, X, y, cv=10)
CC=confusion_matrix(y, pred5)
ACC=(CC[0,0]+CC[1,1])/(CC[0,0]+CC[0,1]+CC[1,0]+CC[1,1])
Sn=CC[0,0]/(CC[0,0]+CC[0,1])
Sp=CC[1,1]/(CC[1,0]+CC[1,1])
MCC=(CC[0,0]*CC[1,1]-CC[1,0]*CC[0,1])/((CC[0,0]+CC[1,0])*(CC[0,0]+CC[0,1])*(CC[1,0]+CC[1,1])*(CC[0,1]+CC[1,1]))**(1/2)
print('ACC:',ACC)
print('Sn:',Sn)
print('Sp:',Sp)
print('MCC:',MCC)

from sklearn.metrics import roc_curve,auc
fpr1,tpr1,threshold1 = roc_curve(y,pred1)
roc_auc1 = auc(fpr1,tpr1)
fpr2,tpr2,threshold2 = roc_curve(y,pred2)
roc_auc2 = auc(fpr2,tpr2)
fpr3,tpr3,threshold3 = roc_curve(y,pred3)
roc_auc3 = auc(fpr3,tpr3)
fpr4,tpr4,threshold4 = roc_curve(y,pred4)
roc_auc4 = auc(fpr4,tpr4)



